# 进度

## 关于训练慢

其实只有highway这个子任务比较慢，十字路口和环岛都挺快的，环岛一分钟能跑4000个step。然后你问问助教能不能修改reward函数，把车限定在马路上，就是在训练的时候修改，eval的时候还是用原来的。感觉这样会快很多。

## 封装

简单的封装已经好了，但是我感觉这个原本的文件就有些问题，后面可能还要参照你的那份改一改。

- main.py 主模块
- makeEnv.py 建造环境
- ReplayBuffer.py 缓存
- SAC.py SAC类和两个网络，store和load我已经加进去了，我还没试过能不能用
- evalApi.py 和eval的交互，一样我还没试过能不能用，那个不同目录下的文件调用好像要写__init__.py，你查一下

## 接下来要做的

### 继续封装

- parse_args，加可以调整的超参
- 网络优化，感觉初始的那个网络怪怪的，可以按你的调一下
- 打印信息和存储tensorboard
- 对gpu的支持，初始版本是不支持gpu的，我看网上说gpu和cpu跑得差不多快是因为没有优化，可以部分任务使用cpu部分使用gpu，这样会比较快。但我感觉这个其实无关紧要，可以留到后面。

### 改reward

你可以去问问助教能不能改reward，可以的话看看怎么改，重写类的话上网搜应该能搜到，还有一种思路是可以看"on_road"这个状态，判断车在不在路上，不在的话直接给一个大的惩罚。从而push车一直在路上。但是这样的话泛化性可能就不够了。

### 开始优化

还有的话我觉得基本可以跑起来（环路）的话可以开始优化了，直接先做priority ReplayBuffer，这个你去找冯奕哲，看他能不能接受，我是觉得再搞一个PPO没有太大的意义。

  ----re: em我确实也觉得意义不是很大，但这样的话在做priority replayBuffer之前是不是就不能调参🤔，还是说我们先调一版，如果冯奕哲同意做replayBuffer的话，等他做好了我们接着再调一下
